import streamlit as st
import os
import json
import torch
import glob
import pandas as pd
from datetime import datetime
import warnings
import random
import numpy as np
import sys
import gc

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.model_manager import model_manager

warnings.filterwarnings('ignore')

# é…ç½®é¡µé¢
st.set_page_config(
    page_title="MiniMind SFTæ¨¡åž‹è¯„ä¼°å·¥å…·",
    page_icon="ðŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å…¨å±€å˜é‡å­˜å‚¨å½“å‰åŠ è½½çš„æ¨¡åž‹
if 'current_model' not in st.session_state:
    st.session_state.current_model = None
    st.session_state.current_tokenizer = None
    st.session_state.current_model_path = None

def setup_seed(seed):
    """è®¾ç½®éšæœºç§å­"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

def get_default_sft_prompts():
    """èŽ·å–é»˜è®¤çš„SFTæµ‹è¯•promptåˆ—è¡¨"""
    return [
        'è¯·ä»‹ç»ä¸€ä¸‹é©¬å…‹æ€ä¸»ä¹‰åŸºæœ¬åŽŸç†',
        'è§£é‡Šä¸€ä¸‹äººç±»å¤§è„‘çš„ä¸»è¦åŠŸèƒ½',
        'ä¸‡æœ‰å¼•åŠ›åŽŸç†æ˜¯ä»€ä¹ˆï¼Ÿ',
        'ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯å“ªä¸€åº§ï¼Ÿ',
        'è¯·å‘Šè¯‰æˆ‘æ­å·žå¸‚æœ‰å“ªäº›è‘—åç¾Žé£Ÿ',
        'å½“å®žéªŒæ•°æ®ä¸Žç†è®ºé¢„æµ‹å‡ºçŽ°åå·®æ—¶ï¼Œç§‘å­¦å®¶é¦–å…ˆåº”è¯¥è€ƒè™‘ä»€ä¹ˆï¼Ÿ',
        'åœ¨é‡å­åŠ›å­¦ä¸­ï¼Œç²’å­çš„çŠ¶æ€æ˜¯ç”±ä»€ä¹ˆæè¿°çš„ï¼Ÿ',
        'ä»€ä¹ˆæ˜¯é‡‘èžå¸‚åœºçš„é»‘å¤©é¹…äº‹ä»¶ï¼Ÿ',
        'åœ¨ç”Ÿç‰©å­¦ä¸­ï¼ŒåŸºå› çªå˜ä¼šå¯¼è‡´ä»€ä¹ˆï¼Ÿ',
        'è¯·è§£é‡Šä¸€ä¸‹è¾¹é™…æ•ˆç”¨é€’å‡è§„å¾‹',
        'å…‰çš„æŠ˜å°„çŽ‡ä¸Žä»€ä¹ˆæœ‰å…³ï¼Ÿ',
        'åŒ–å­¦ååº”çš„é€ŸçŽ‡ä¸Žå“ªäº›å› ç´ æœ‰å…³ï¼Ÿ',
        'åŒºå—é“¾æŠ€æœ¯çš„ä¸å¯ç¯¡æ”¹æ€§ä¸»è¦ä¾èµ–äºŽä»€ä¹ˆï¼Ÿ',
        'è¯·å¸®æˆ‘å†™ä¸€é¦–å…³äºŽæ˜¥å¤©çš„è¯—',
        'å¦‚ä½•å­¦ä¹ ç¼–ç¨‹ï¼Ÿ',
        'è¯·æŽ¨èå‡ æœ¬å¥½çœ‹çš„ç§‘å¹»å°è¯´',
        'æ€Žæ ·ä¿æŒèº«ä½“å¥åº·ï¼Ÿ',
        'è¯·è§£é‡Šä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•åŽ†ç¨‹',
        'å¦‚ä½•æé«˜å·¥ä½œæ•ˆçŽ‡ï¼Ÿ',
        'è¯·ä»‹ç»ä¸€ä¸‹ä¸­å›½çš„ä¼ ç»ŸèŠ‚æ—¥',
        # å¯¹è¯å¼é—®é¢˜
        'ä½ æ˜¯è°ï¼Ÿä½ èƒ½åšä»€ä¹ˆï¼Ÿ',
        'è¯·å¸®æˆ‘åˆ¶å®šä¸€ä¸ªå­¦ä¹ è®¡åˆ’',
        'æˆ‘æ„Ÿåˆ°å¾ˆç„¦è™‘ï¼Œä½ èƒ½ç»™æˆ‘ä¸€äº›å»ºè®®å—ï¼Ÿ',
        'è¯·å¸®æˆ‘åˆ†æžä¸€ä¸‹è¿™ä¸ªé—®é¢˜çš„è§£å†³æ–¹æ¡ˆ',
        'ä½ è§‰å¾—äººå·¥æ™ºèƒ½ä¼šå–ä»£äººç±»å—ï¼Ÿ',
    ]

def main():
    st.title("ðŸ¤– MiniMind SFTæ¨¡åž‹è¯„ä¼°å·¥å…·")
    st.markdown("---")
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3 = st.tabs(["ðŸ”§ æ¨¡åž‹ç®¡ç†", "ðŸ§ª æ¨¡åž‹æµ‹è¯•", "ðŸ“Š åŽ†å²ç»“æžœ"])
    
    with tab1:
        st.header("SFTæ¨¡åž‹ç®¡ç†")
        
        # èŽ·å–å¯ç”¨æ¨¡åž‹
        available_models = model_manager.get_available_sft_models()
        
        if not available_models:
            st.error("æœªæ‰¾åˆ°SFTæ¨¡åž‹æ–‡ä»¶ï¼Œè¯·ç¡®ä¿out/sftç›®å½•ä¸‹æœ‰æ¨¡åž‹æ–‡ä»¶")
            st.info("ðŸ’¡ æç¤ºï¼šè¿è¡ŒSFTè®­ç»ƒåŽï¼Œæ¨¡åž‹ä¼šä¿å­˜åœ¨out/sftç›®å½•ä¸‹")
        else:
            # æ¨¡åž‹é€‰æ‹©åŒºåŸŸ
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.subheader("é€‰æ‹©SFTæ¨¡åž‹")
                
                # æ¨¡åž‹é€‰æ‹©
                model_options = ["è¯·é€‰æ‹©æ¨¡åž‹"] + available_models
                selected_model = st.selectbox(
                    "é€‰æ‹©SFTæ¨¡åž‹",
                    model_options,
                    index=0
                )
                
                # æ¨¡åž‹å‚æ•°é…ç½®
                col_param1, col_param2, col_param3 = st.columns(3)
                with col_param1:
                    hidden_size = st.selectbox(
                        "Hidden Size",
                        [512, 640, 768],
                        index=0
                    )
                
                with col_param2:
                    num_hidden_layers = st.selectbox(
                        "Hidden Layers", 
                        [8, 16],
                        index=0
                    )
                
                with col_param3:
                    use_moe = st.checkbox("ä½¿ç”¨MoE")
                
                # æ¨¡åž‹æ“ä½œæŒ‰é’®
                col_btn1, col_btn2 = st.columns(2)
                with col_btn1:
                    load_button = st.button("ðŸ”„ åŠ è½½æ¨¡åž‹", type="primary", disabled=(selected_model == "è¯·é€‰æ‹©æ¨¡åž‹"))
                with col_btn2:
                    unload_button = st.button("ðŸ—‘ï¸ å¸è½½æ¨¡åž‹", disabled=(model_manager.current_model is None))
                
                # å¤„ç†åŠ è½½æ¨¡åž‹
                if load_button and selected_model != "è¯·é€‰æ‹©æ¨¡åž‹":
                    model_path = f"./out/sft/{selected_model}"
                    with st.spinner("æ­£åœ¨åŠ è½½SFTæ¨¡åž‹..."):
                        success, message = model_manager.load_sft_model(model_path, hidden_size, num_hidden_layers, use_moe)
                        if success:
                            st.success(message)
                            st.rerun()
                        else:
                            st.error(message)
                
                # å¤„ç†å¸è½½æ¨¡åž‹
                if unload_button:
                    model_manager.unload_model()
                    st.success("æ¨¡åž‹å·²å¸è½½")
                    st.rerun()
            
            with col2:
                st.subheader("å½“å‰çŠ¶æ€")
                # æ˜¾ç¤ºå½“å‰æ¨¡åž‹çŠ¶æ€
                if model_manager.current_model is not None:
                    st.success("âœ… æ¨¡åž‹å·²åŠ è½½")
                    st.info(f"æ¨¡åž‹: {os.path.basename(model_manager.current_model_path)}")
                    
                    # æ˜¾ç¤ºæ¨¡åž‹å‚æ•°ä¿¡æ¯
                    param_count = sum(p.numel() for p in model_manager.current_model.parameters() if p.requires_grad) / 1e6
                    st.metric("å‚æ•°é‡", f"{param_count:.2f}M")
                else:
                    st.warning("âš ï¸ æœªåŠ è½½æ¨¡åž‹")
                    st.info("è¯·é€‰æ‹©æ¨¡åž‹å¹¶ç‚¹å‡»åŠ è½½æŒ‰é’®")
    
    with tab2:
        st.header("SFTæ¨¡åž‹æµ‹è¯•")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åŠ è½½çš„æ¨¡åž‹
        if model_manager.current_model is None:
            st.warning("âš ï¸ è¯·å…ˆåœ¨ã€Žæ¨¡åž‹ç®¡ç†ã€æ ‡ç­¾é¡µä¸­åŠ è½½SFTæ¨¡åž‹")
            st.info("ðŸ’¡ æç¤ºï¼šåˆ‡æ¢åˆ°ã€Žæ¨¡åž‹ç®¡ç†ã€æ ‡ç­¾é¡µï¼Œé€‰æ‹©æ¨¡åž‹å¹¶ç‚¹å‡»ã€ŽåŠ è½½æ¨¡åž‹ã€æŒ‰é’®")
        
        # æµ‹è¯•è¾“å…¥åŒºåŸŸ
        col1, col2 = st.columns([3, 1])
        
        with col1:
            # System Promptè®¾ç½®
            st.subheader("System Prompt")
            system_prompt = st.text_area(
                "è®¾ç½®System Prompt",
                value="you are a helpful assistant",
                height=100,
                help="è®¾ç½®æ¨¡åž‹çš„è§’è‰²å’Œè¡Œä¸ºæŒ‡å¯¼"
            )
            
            # é»˜è®¤prompt
            default_prompts = get_default_sft_prompts()
            
            # å°†é»˜è®¤promptsè½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼
            default_text = '\n'.join(default_prompts)
            
            # ç›´æŽ¥ä½¿ç”¨æ–‡æœ¬è¾“å…¥
            custom_input = st.text_area(
                "æµ‹è¯•Promptsï¼ˆæ¯è¡Œä¸€ä¸ªpromptï¼‰",
                value=default_text,
                height=250,
                placeholder="è¯·è¾“å…¥æµ‹è¯•å†…å®¹ï¼Œæ¯è¡Œä¸€ä¸ªprompt",
                help="å¯ä»¥ç›´æŽ¥ç¼–è¾‘é»˜è®¤promptsï¼Œæˆ–è€…æ·»åŠ æ–°çš„æµ‹è¯•å†…å®¹",
                key="sft_prompt_input"
            )
            
            test_prompts = [line.strip() for line in custom_input.split('\n') if line.strip()]
        
        with col2:
            # ç”Ÿæˆå‚æ•°
            st.subheader("ç”Ÿæˆå‚æ•°")
            max_length = st.slider("æœ€å¤§ç”Ÿæˆé•¿åº¦", 50, 1024, 256)
            temperature = st.slider("Temperature", 0.1, 2.0, 0.85)
            top_p = st.slider("Top-p", 0.1, 1.0, 0.85)
            
            # æ‰§è¡Œæ¬¡æ•°
            num_runs = st.number_input("æ‰§è¡Œæ¬¡æ•°", min_value=1, max_value=10, value=3)
            
            # éšæœºç§å­è®¾ç½®
            use_fixed_seed = st.checkbox("ä½¿ç”¨å›ºå®šç§å­")
            if use_fixed_seed:
                fixed_seed = st.number_input("éšæœºç§å­", value=2025)
            
            # å¤‡æ³¨ä¿¡æ¯
            st.markdown("---")
            test_note = st.text_area(
                "æµ‹è¯•å¤‡æ³¨",
                placeholder="ä¸ºæœ¬æ¬¡æµ‹è¯•æ·»åŠ å¤‡æ³¨ä¿¡æ¯...",
                height=80,
                help="å¯ä»¥è®°å½•æµ‹è¯•ç›®çš„ã€å‚æ•°è°ƒæ•´åŽŸå› ç­‰ä¿¡æ¯"
            )
        
        # å¼€å§‹æµ‹è¯•æŒ‰é’®
        if st.button("ðŸš€ å¼€å§‹æµ‹è¯•", type="primary", disabled=len(test_prompts) == 0):
            if not test_prompts:
                st.error("è¯·å…ˆé€‰æ‹©æˆ–è¾“å…¥æµ‹è¯•å†…å®¹")
                return
            
            # æ‰§è¡Œæµ‹è¯•
            all_results = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            results_container = st.container()
            
            total_tests = len(test_prompts) * num_runs
            current_test = 0
            
            for run_idx in range(num_runs):
                run_results = []
                
                for prompt_idx, prompt in enumerate(test_prompts):
                    current_test += 1
                    progress = current_test / total_tests
                    progress_bar.progress(progress)
                    status_text.text(f"æ‰§è¡Œç¬¬ {run_idx + 1} è½®ï¼Œæµ‹è¯• {prompt_idx + 1}/{len(test_prompts)}: {prompt[:30]}...")
                    
                    # è®¾ç½®éšæœºç§å­
                    if use_fixed_seed:
                        setup_seed(fixed_seed)
                    else:
                        setup_seed(random.randint(0, 20480))
                    
                    # ç”Ÿæˆæ–‡æœ¬
                    response = model_manager.generate_text_sft(
                        prompt=prompt,
                        system_prompt=system_prompt,
                        max_length=max_length,
                        temperature=temperature,
                        top_p=top_p
                    )
                    
                    result = {
                        "run": run_idx + 1,
                        "prompt": prompt,
                        "response": response,
                        "system_prompt": system_prompt,
                        "timestamp": datetime.now().isoformat(),
                        "parameters": {
                            "max_length": max_length,
                            "temperature": temperature,
                            "top_p": top_p
                        }
                    }
                    run_results.append(result)
                
                all_results.extend(run_results)
            
            progress_bar.progress(1.0)
            status_text.text("æµ‹è¯•å®Œæˆï¼")
            
            # ä¿å­˜ç»“æžœ
            model_name = os.path.basename(model_manager.current_model_path).replace('.pth', '')
            saved_file = model_manager.save_evaluation_results(all_results, model_name, "sft", test_note)
            st.success(f"æµ‹è¯•ç»“æžœå·²ä¿å­˜åˆ°: {saved_file}")
    
    with tab3:
        st.header("åŽ†å²æµ‹è¯•ç»“æžœ")
        
        # åŠ è½½åŽ†å²æ•°æ®
        history_data = model_manager.load_evaluation_history("sft")
        
        if not history_data:
            st.info("ðŸ“‹ æš‚æ— åŽ†å²æµ‹è¯•ç»“æžœ")
            st.markdown("ðŸ’¡ **æç¤º**: åœ¨ã€Žæ¨¡åž‹æµ‹è¯•ã€æ ‡ç­¾é¡µä¸­è¿è¡Œæµ‹è¯•åŽï¼Œç»“æžœä¼šæ˜¾ç¤ºåœ¨è¿™é‡Œ")
            return
        
        # åŽ†å²ç»“æžœç®¡ç†åŒºåŸŸ
        col_select, col_delete = st.columns([4, 1])
        
        with col_select:
            # é€‰æ‹©åŽ†å²æ–‡ä»¶
            history_options = [
                f"{item['timestamp']} - {item['model_name']} ({item['num_tests']}ä¸ªæµ‹è¯•)" + 
                (f" - {item['note'][:30]}..." if item['note'] and len(item['note']) > 30 else f" - {item['note']}" if item['note'] else "")
                for item in history_data
            ]
            
            selected_history = st.selectbox(
                "é€‰æ‹©åŽ†å²ç»“æžœ",
                range(len(history_options)),
                format_func=lambda x: history_options[x]
            )
        
        with col_delete:
            st.markdown("ã€€")  # å ä½ç¬¦ï¼Œå¯¹é½é€‰æ‹©æ¡†
            delete_button = st.button("ðŸ—‘ï¸ åˆ é™¤é€‰ä¸­ç»“æžœ", type="secondary")
        
        # å¤„ç†åˆ é™¤æ“ä½œ
        if delete_button and selected_history is not None:
            selected_file_path = history_data[selected_history]['file_path']
            selected_filename = history_data[selected_history]['filename']
            
            os.remove(selected_file_path)
            st.success(f"âœ… å·²åˆ é™¤ç»“æžœæ–‡ä»¶: {selected_filename}")
        
        # æ˜¾ç¤ºé€‰ä¸­çš„åŽ†å²ç»“æžœ
        if selected_history is not None and not delete_button:
            selected_data = history_data[selected_history]['data']
            selected_file_path = history_data[selected_history]['file_path']
            
            st.markdown("---")
            
            # æ˜¾ç¤ºæ¦‚è§ˆä¿¡æ¯
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("æµ‹è¯•æ—¶é—´", selected_data['timestamp'])
            with col2:
                st.metric("æ¨¡åž‹åç§°", selected_data['model_name'])
            with col3:
                st.metric("æµ‹è¯•æ•°é‡", len(selected_data['results']))
            with col4:
                # è®¡ç®—å¹³å‡å“åº”é•¿åº¦
                avg_length = np.mean([len(r['response']) for r in selected_data['results']])
                st.metric("å¹³å‡å“åº”é•¿åº¦", f"{avg_length:.1f}")
            
            # System Promptæ˜¾ç¤º
            if selected_data['results'] and 'system_prompt' in selected_data['results'][0]:
                st.subheader("System Prompt")
                st.code(selected_data['results'][0]['system_prompt'])
            
            # å¤‡æ³¨ä¿¡æ¯æ˜¾ç¤ºå’Œç¼–è¾‘
            st.markdown("---")
            st.subheader("æµ‹è¯•å¤‡æ³¨")
            
            # ä½¿ç”¨session stateæ¥ç®¡ç†ç¼–è¾‘æ¨¡å¼
            edit_key = f"edit_note_{selected_history}"
            if edit_key not in st.session_state:
                st.session_state[edit_key] = False
            
            current_note = selected_data.get('note', '')
            
            if not st.session_state[edit_key]:
                # æ˜¾ç¤ºæ¨¡å¼
                col_note1, col_note2 = st.columns([4, 1])
                with col_note1:
                    if current_note:
                        st.text_area("", value=current_note, height=80, disabled=True, key=f"note_display_{selected_history}")
                    else:
                        st.text("æš‚æ— å¤‡æ³¨ä¿¡æ¯")
                with col_note2:
                    if st.button("ç¼–è¾‘å¤‡æ³¨", key=f"edit_btn_{selected_history}"):
                        st.session_state[edit_key] = True
                        st.rerun()
            else:
                # ç¼–è¾‘æ¨¡å¼
                new_note = st.text_area(
                    "ç¼–è¾‘å¤‡æ³¨",
                    value=current_note,
                    height=80,
                    key=f"note_edit_{selected_history}"
                )
                col_save1, col_save2, col_save3 = st.columns([1, 1, 3])
                with col_save1:
                    if st.button("ä¿å­˜", key=f"save_btn_{selected_history}"):
                        # æ›´æ–°JSONæ–‡ä»¶
                        selected_data['note'] = new_note
                        with open(selected_file_path, 'w', encoding='utf-8') as f:
                            json.dump(selected_data, f, ensure_ascii=False, indent=2)
                        st.session_state[edit_key] = False
                        st.success("å¤‡æ³¨å·²æ›´æ–°")
                        st.rerun()
                with col_save2:
                    if st.button("å–æ¶ˆ", key=f"cancel_btn_{selected_history}"):
                        st.session_state[edit_key] = False
                        st.rerun()
            
            st.markdown("---")
            
            # åˆ›å»ºç»“æžœè¡¨æ ¼
            results_df = pd.DataFrame([
                {
                    "è½®æ¬¡": r['run'],
                    "è¾“å…¥": r['prompt'][:50] + "..." if len(r['prompt']) > 50 else r['prompt'],
                    "è¾“å‡º": r['response'][:100] + "..." if len(r['response']) > 100 else r['response'],
                    "è¾“å‡ºé•¿åº¦": len(r['response']),
                    "æ—¶é—´": r['timestamp']
                }
                for r in selected_data['results']
            ])
            
            st.dataframe(results_df, use_container_width=True)
            
            # è¯¦ç»†æŸ¥çœ‹
            st.subheader("è¯¦ç»†ç»“æžœ")
            for i, result in enumerate(selected_data['results']):
                with st.expander(f"ç¬¬{result['run']}è½® - {result['prompt'][:50]}..."):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.text_area(
                            "è¾“å…¥",
                            result['prompt'],
                            height=100,
                            disabled=True,
                            key=f"sft_hist_input_{i}"
                        )
                    with col2:
                        st.text_area(
                            "è¾“å‡º", 
                            result['response'],
                            height=100,
                            disabled=True,
                            key=f"sft_hist_output_{i}"
                        )

if __name__ == "__main__":
    main()