# MiniMind é¢„è®­ç»ƒè¿‡ç¨‹æŠ€æœ¯è§£è¯»

## ğŸ“‹ å‰è¨€

è¿™ä»½æ–‡æ¡£å°†ä»æŠ€æœ¯è§’åº¦è¯¦ç»†è§£è¯» MiniMind é¡¹ç›®çš„é¢„è®­ç»ƒè¿‡ç¨‹ã€‚é€‚åˆå…·æœ‰ Python åŸºç¡€ä½†åˆšæ¥è§¦ AI é¢†åŸŸçš„å¼€å‘è€…é˜…è¯»ã€‚æˆ‘ä»¬å°†æ·±å…¥åˆ†ææ¯ä¸ªå…³é”®æ¨¡å—çš„å®ç°åŸç†å’Œä»£ç ç»†èŠ‚ã€‚

## ğŸ¯ ä»€ä¹ˆæ˜¯é¢„è®­ç»ƒï¼Ÿ

**é¢„è®­ç»ƒ(Pre-training)** æ˜¯å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒçš„ç¬¬ä¸€ä¸ªé˜¶æ®µï¼Œç›®æ ‡æ˜¯è®©æ¨¡å‹ä»å¤§é‡æ— æ ‡ç­¾æ–‡æœ¬ä¸­å­¦ä¹ è¯­è¨€çš„åŸºæœ¬è§„å¾‹ï¼š

- **è¯­è¨€å»ºæ¨¡**ï¼šé¢„æµ‹ä¸‹ä¸€ä¸ªè¯æ˜¯ä»€ä¹ˆ
- **è¯­æ³•å­¦ä¹ **ï¼šç†è§£å¥å­ç»“æ„å’Œè¯­æ³•è§„åˆ™
- **çŸ¥è¯†ç§¯ç´¯**ï¼šä»æ–‡æœ¬ä¸­å­¦ä¹ äº‹å®æ€§çŸ¥è¯†
- **è¯­ä¹‰ç†è§£**ï¼šç†è§£è¯æ±‡å’Œå¥å­çš„å«ä¹‰

ç®€å•æ¥è¯´ï¼Œé¢„è®­ç»ƒå°±åƒæ•™å°å­©è¯»ä¹¦è¯†å­—çš„è¿‡ç¨‹ï¼Œé€šè¿‡å¤§é‡é˜…è¯»è®©æ¨¡å‹"æ‡‚è¯­è¨€"ã€‚

## ğŸ—ï¸ MiniMind æ¨¡å‹æ¶æ„è§£æ

### æ•´ä½“æ¶æ„è®¾è®¡

MiniMind é‡‡ç”¨äº†ç»å…¸çš„ **Transformer Decoder** æ¶æ„ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹ç»„ä»¶ï¼š

```python
class MiniMindForCausalLM(PreTrainedModel, GenerationMixin):
    def __init__(self, config: MiniMindConfig = None):
        self.model = MiniMindModel(self.config)          # æ ¸å¿ƒæ¨¡å‹
        self.lm_head = nn.Linear(..., vocab_size)        # è¾“å‡ºå±‚
        self.model.embed_tokens.weight = self.lm_head.weight  # æƒé‡å…±äº«
```

**å…³é”®è®¾è®¡ç†å¿µ**ï¼š
- **æƒé‡å…±äº«**ï¼šè¾“å…¥åµŒå…¥å±‚å’Œè¾“å‡ºå±‚å…±äº«æƒé‡ï¼Œå‡å°‘å‚æ•°é‡
- **å› æœå»ºæ¨¡**ï¼šåªèƒ½çœ‹åˆ°å½“å‰ä½ç½®ä¹‹å‰çš„å†…å®¹ï¼Œé€‚åˆæ–‡æœ¬ç”Ÿæˆ

### 1. è¯åµŒå…¥å±‚ (Token Embedding)

```python
self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size)
```

**ä½œç”¨**ï¼šå°†è¯æ±‡IDè½¬æ¢ä¸ºå‘é‡è¡¨ç¤º
- **vocab_size**: è¯æ±‡è¡¨å¤§å° (6400)
- **hidden_size**: éšè—å±‚ç»´åº¦ (512)

**å®ä¾‹**ï¼š
```python
# è¯æ±‡ "ä½ å¥½" çš„IDæ˜¯ 1234ï¼Œè½¬æ¢ä¸º 512 ç»´å‘é‡
word_id = 1234
embedding = embed_tokens(word_id)  # shape: [512]
```

### 2. ä½ç½®ç¼–ç  - RoPEï¼ˆæ—‹è½¬ä½ç½®ç¼–ç ï¼‰

MiniMind ä½¿ç”¨äº† **RoPE (Rotary Position Embedding)** æ¥å¤„ç†åºåˆ—ä¸­è¯æ±‡çš„ä½ç½®ä¿¡æ¯ï¼š

```python
def precompute_freqs_cis(dim: int, end: int = int(32 * 1024), theta: float = 1e6):
    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))
    t = torch.arange(end, device=freqs.device)
    freqs = torch.outer(t, freqs).float()
    freqs_cos = torch.cat([torch.cos(freqs), torch.cos(freqs)], dim=-1)
    freqs_sin = torch.cat([torch.sin(freqs), torch.sin(freqs)], dim=-1)
    return freqs_cos, freqs_sin
```

**RoPE çš„æ ¸å¿ƒæ€æƒ³**ï¼š
- é€šè¿‡æ—‹è½¬å˜æ¢æ¥ç¼–ç ä½ç½®ä¿¡æ¯
- ä¸éœ€è¦é¢å¤–çš„ä½ç½®åµŒå…¥å‚æ•°
- èƒ½æ›´å¥½åœ°å¤„ç†é•¿åºåˆ—

**æ•°å­¦åŸç†ç®€åŒ–ç†è§£**ï¼š
```python
# å¯¹äºä½ç½® pos çš„è¯æ±‡ï¼Œå…¶å‘é‡ä¼šè¢«"æ—‹è½¬"ä¸€ä¸ªè§’åº¦
# è§’åº¦ = pos * frequency
# è¿™æ ·ä¸åŒä½ç½®çš„è¯æ±‡å‘é‡ä¼šæœ‰ä¸åŒçš„"æ—‹è½¬"ï¼Œæ¨¡å‹å°±èƒ½åŒºåˆ†ä½ç½®
```

### 3. å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ (Multi-Head Attention)

```python
class Attention(nn.Module):
    def __init__(self, args: MiniMindConfig):
        self.num_key_value_heads = 2  # KVå¤´æ•°é‡
        self.n_local_heads = 8        # Queryå¤´æ•°é‡
        self.head_dim = 64            # æ¯ä¸ªå¤´çš„ç»´åº¦
        
        self.q_proj = nn.Linear(hidden_size, num_heads * head_dim)
        self.k_proj = nn.Linear(hidden_size, num_kv_heads * head_dim) 
        self.v_proj = nn.Linear(hidden_size, num_kv_heads * head_dim)
        self.o_proj = nn.Linear(num_heads * head_dim, hidden_size)
```

**æ³¨æ„åŠ›æœºåˆ¶æ ¸å¿ƒæ­¥éª¤**ï¼š

1. **æŠ•å½±å˜æ¢**ï¼š
```python
Q = self.q_proj(x)  # Query: æŸ¥è¯¢å‘é‡
K = self.k_proj(x)  # Key: é”®å‘é‡  
V = self.v_proj(x)  # Value: å€¼å‘é‡
```

2. **è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°**ï¼š
```python
scores = Q @ K.transpose(-2, -1) / math.sqrt(self.head_dim)
```

3. **åº”ç”¨å› æœæ©ç **ï¼š
```python
# ç¡®ä¿åªèƒ½çœ‹åˆ°å½“å‰ä½ç½®ä¹‹å‰çš„å†…å®¹
mask = torch.triu(torch.full((seq_len, seq_len), float("-inf")), diagonal=1)
scores = scores + mask
```

4. **softmaxå½’ä¸€åŒ–**ï¼š
```python
attention_weights = F.softmax(scores, dim=-1)
```

5. **åŠ æƒæ±‚å’Œ**ï¼š
```python
output = attention_weights @ V
```

**GQA (Grouped Query Attention)**ï¼š
MiniMind ä½¿ç”¨äº† GQA æŠ€æœ¯ï¼ŒKå’ŒVå¤´æ•°é‡å°‘äºQå¤´æ•°é‡ï¼Œé€šè¿‡å¤åˆ¶æ¥åŒ¹é…ï¼š
```python
def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:
    # å°† KV å¤´å¤åˆ¶å¤šæ¬¡ä»¥åŒ¹é… Q å¤´æ•°é‡
    return x.repeat_interleave(n_rep, dim=2)
```

### 4. å‰é¦ˆç½‘ç»œ (Feed Forward Network)

```python
class FeedForward(nn.Module):
    def __init__(self, config: MiniMindConfig):
        intermediate_size = int(config.hidden_size * 8 / 3)  # çº¦1365
        self.gate_proj = nn.Linear(hidden_size, intermediate_size)
        self.up_proj = nn.Linear(hidden_size, intermediate_size) 
        self.down_proj = nn.Linear(intermediate_size, hidden_size)
        self.act_fn = SiLU()  # Swishæ¿€æ´»å‡½æ•°
    
    def forward(self, x):
        # SwiGLU: é—¨æ§çº¿æ€§å•å…ƒ
        return self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
```

**SwiGLU åŸç†**ï¼š
- ç»“åˆäº† Swish æ¿€æ´»å‡½æ•°å’Œé—¨æ§æœºåˆ¶
- `gate_proj` äº§ç”Ÿé—¨æ§ä¿¡å·
- `up_proj` äº§ç”Ÿç‰¹å¾ä¿¡å·
- ä¸¤è€…ç›¸ä¹˜å®ç°ç‰¹å¾é€‰æ‹©

### 5. RMS Layer Normalization

```python
class RMSNorm(torch.nn.Module):
    def __init__(self, dim: int, eps: float = 1e-5):
        self.eps = eps
        self.weight = nn.Parameter(torch.ones(dim))
    
    def _norm(self, x):
        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)
    
    def forward(self, x):
        return self.weight * self._norm(x.float()).type_as(x)
```

**RMSNorm vs LayerNorm**ï¼š
- RMSNorm åªè¿›è¡Œç¼©æ”¾æ ‡å‡†åŒ–ï¼Œä¸å‡å»å‡å€¼
- è®¡ç®—æ›´ç®€å•ï¼Œæ€§èƒ½æ›´å¥½
- åœ¨å¤§è¯­è¨€æ¨¡å‹ä¸­æ•ˆæœä¸ LayerNorm ç›¸å½“

### 6. Transformer Block

```python
class MiniMindBlock(nn.Module):
    def forward(self, hidden_states, position_embeddings, ...):
        # Pre-Norm æ¶æ„
        residual = hidden_states
        
        # 1. æ³¨æ„åŠ›å­å±‚
        hidden_states, present_key_value = self.self_attn(
            self.input_layernorm(hidden_states),  # å…ˆå½’ä¸€åŒ–
            position_embeddings, ...
        )
        hidden_states += residual  # æ®‹å·®è¿æ¥
        
        # 2. å‰é¦ˆå­å±‚
        hidden_states = hidden_states + self.mlp(
            self.post_attention_layernorm(hidden_states)
        )
        return hidden_states, present_key_value
```

**Pre-Norm æ¶æ„ä¼˜åŠ¿**ï¼š
- è®­ç»ƒæ›´ç¨³å®š
- æ¢¯åº¦æµåŠ¨æ›´å¥½
- é€‚åˆæ·±å±‚ç½‘ç»œ

## ğŸ“Š æ•°æ®å¤„ç†æµç¨‹

### 1. æ•°æ®é›†æ ¼å¼

```json
{"text": "è¿™æ˜¯ä¸€ä¸ªç”¨äºé¢„è®­ç»ƒçš„æ–‡æœ¬æ ·æœ¬ã€‚æ¨¡å‹éœ€è¦å­¦ä¹ é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ã€‚"}
{"text": "å¦ä¸€ä¸ªè®­ç»ƒæ ·æœ¬ï¼ŒåŒ…å«ä¸°å¯Œçš„è¯­è¨€çŸ¥è¯†å’Œå¸¸è¯†ã€‚"}
```

### 2. æ•°æ®åŠ è½½å™¨å®ç°

```python
class PretrainDataset(Dataset):
    def __getitem__(self, index):
        sample = self.samples[index]
        
        # åˆ†è¯ç¼–ç 
        encoding = self.tokenizer(
            str(sample['text']),
            max_length=self.max_length,     # æœ€å¤§é•¿åº¦512
            padding='max_length',           # å¡«å……åˆ°å›ºå®šé•¿åº¦
            truncation=True,               # æˆªæ–­è¶…é•¿æ–‡æœ¬
            return_tensors='pt'
        )
        
        input_ids = encoding.input_ids.squeeze()
        loss_mask = (input_ids != self.tokenizer.pad_token_id)
        
        # æ„é€ è®­ç»ƒæ ·æœ¬å¯¹
        X = torch.tensor(input_ids[:-1], dtype=torch.long)  # è¾“å…¥åºåˆ—
        Y = torch.tensor(input_ids[1:], dtype=torch.long)   # ç›®æ ‡åºåˆ—ï¼ˆå³ç§»ä¸€ä½ï¼‰
        loss_mask = torch.tensor(loss_mask[1:], dtype=torch.long)  # æŸå¤±æ©ç 
        
        return X, Y, loss_mask
```

**æ•°æ®å¤„ç†å…³é”®æ­¥éª¤**ï¼š

1. **åºåˆ—æ„é€ **ï¼š
```python
# åŸå§‹æ–‡æœ¬: "æˆ‘ çˆ± ç¼–ç¨‹"
# åˆ†è¯åID: [123, 456, 789, 2]  # 2æ˜¯ç»“æŸç¬¦

# æ„é€ è®­ç»ƒå¯¹ï¼š
X = [123, 456, 789]    # è¾“å…¥ï¼šå‰n-1ä¸ªè¯
Y = [456, 789, 2]      # ç›®æ ‡ï¼šån-1ä¸ªè¯
```

2. **æŸå¤±æ©ç **ï¼š
```python
# åªåœ¨éå¡«å……ä½ç½®è®¡ç®—æŸå¤±
loss_mask = [1, 1, 1, 0, 0, ...]  # 1è¡¨ç¤ºè®¡ç®—æŸå¤±ï¼Œ0è¡¨ç¤ºå¿½ç•¥
```

## ğŸ“ è®­ç»ƒè¿‡ç¨‹è¯¦è§£

### 1. æ ¸å¿ƒè®­ç»ƒå¾ªç¯

```python
def train_epoch(epoch, wandb):
    loss_fct = nn.CrossEntropyLoss(reduction='none')
    
    for step, (X, Y, loss_mask) in enumerate(train_loader):
        X = X.to(args.device)      # è¾“å…¥åºåˆ—
        Y = Y.to(args.device)      # ç›®æ ‡åºåˆ—
        loss_mask = loss_mask.to(args.device)  # æŸå¤±æ©ç 
        
        # åŠ¨æ€å­¦ä¹ ç‡è°ƒæ•´
        lr = get_lr(current_step, total_steps, base_lr)
        for param_group in optimizer.param_groups:
            param_group['lr'] = lr
        
        # å‰å‘ä¼ æ’­
        with ctx:  # è‡ªåŠ¨æ··åˆç²¾åº¦
            res = model(X)
            loss = loss_fct(
                res.logits.view(-1, res.logits.size(-1)),  # å±•å¹³é¢„æµ‹
                Y.view(-1)                                  # å±•å¹³ç›®æ ‡
            ).view(Y.size())
            
            # åªåœ¨æœ‰æ•ˆä½ç½®è®¡ç®—æŸå¤±
            loss = (loss * loss_mask).sum() / loss_mask.sum()
            loss += res.aux_loss  # MoEè¾…åŠ©æŸå¤±
            loss = loss / args.accumulation_steps  # æ¢¯åº¦ç´¯ç§¯
        
        # åå‘ä¼ æ’­
        scaler.scale(loss).backward()
        
        # æ¢¯åº¦æ›´æ–°
        if (step + 1) % args.accumulation_steps == 0:
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)
            scaler.step(optimizer)
            scaler.update()
            optimizer.zero_grad(set_to_none=True)
```

### 2. æŸå¤±å‡½æ•°è¯¦è§£

**äº¤å‰ç†µæŸå¤±**æ˜¯è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒçš„æ ‡å‡†æŸå¤±å‡½æ•°ï¼š

```python
# å¯¹äºæ¯ä¸ªä½ç½®ï¼Œè®¡ç®—é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒä¸çœŸå®æ ‡ç­¾çš„äº¤å‰ç†µ
loss = -log(P(y_true | context))

# å®é™…è®¡ç®—ä¸­ï¼š
logits = model(X)              # å½¢çŠ¶: [batch, seq_len, vocab_size]
probs = F.softmax(logits, dim=-1)    # è½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒ
loss = F.cross_entropy(logits.view(-1, vocab_size), Y.view(-1))
```

**ä¸ºä»€ä¹ˆä½¿ç”¨äº¤å‰ç†µ**ï¼š
- è¡¡é‡é¢„æµ‹åˆ†å¸ƒä¸çœŸå®åˆ†å¸ƒçš„å·®å¼‚
- å¯¹é”™è¯¯é¢„æµ‹æœ‰è¾ƒå¤§æƒ©ç½š
- æ¢¯åº¦æ€§è´¨è‰¯å¥½ï¼Œé€‚åˆä¼˜åŒ–

### 3. å­¦ä¹ ç‡è°ƒåº¦

```python
def get_lr(current_step, total_steps, lr):
    # ä½™å¼¦è¡°å‡å­¦ä¹ ç‡
    return lr / 10 + 0.5 * lr * (1 + math.cos(math.pi * current_step / total_steps))
```

**å­¦ä¹ ç‡ç­–ç•¥**ï¼š
- åˆå§‹å€¼ï¼š`5e-4`
- æœ€å°å€¼ï¼š`lr/10 = 5e-5`
- ä½¿ç”¨ä½™å¼¦è¡°å‡ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­é€æ¸é™ä½

### 4. ä¼˜åŒ–æŠ€æœ¯

**æ¢¯åº¦ç´¯ç§¯**ï¼š
```python
loss = loss / args.accumulation_steps  # ç´¯ç§¯8æ­¥
if (step + 1) % 8 == 0:
    optimizer.step()  # æ¯8æ­¥æ›´æ–°ä¸€æ¬¡
```
- æ¨¡æ‹Ÿå¤§æ‰¹æ¬¡è®­ç»ƒæ•ˆæœ
- å‡å°‘æ˜¾å­˜å ç”¨

**æ¢¯åº¦è£å‰ª**ï¼š
```python
torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
```
- é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
- æé«˜è®­ç»ƒç¨³å®šæ€§

**æ··åˆç²¾åº¦è®­ç»ƒ**ï¼š
```python
scaler = torch.cuda.amp.GradScaler()
with torch.cuda.amp.autocast():
    loss = model(X)
scaler.scale(loss).backward()
```
- ä½¿ç”¨ FP16 æé«˜è®­ç»ƒé€Ÿåº¦
- å‡å°‘æ˜¾å­˜å ç”¨

## ğŸ”§ å…³é”®æŠ€æœ¯è§£æ

### 1. KV-Cache æœºåˆ¶

```python
def forward(self, x, past_key_value=None, use_cache=False):
    # è®¡ç®—å½“å‰Q, K, V
    xq, xk, xv = self.q_proj(x), self.k_proj(x), self.v_proj(x)
    
    # å¦‚æœæœ‰ç¼“å­˜ï¼Œæ‹¼æ¥å†å²K, V
    if past_key_value is not None:
        xk = torch.cat([past_key_value[0], xk], dim=1)
        xv = torch.cat([past_key_value[1], xv], dim=1)
    
    # ä¿å­˜å½“å‰K, Vç”¨äºä¸‹æ¬¡æ¨ç†
    past_kv = (xk, xv) if use_cache else None
    
    return output, past_kv
```

**KV-Cache ä½œç”¨**ï¼š
- é¿å…é‡å¤è®¡ç®—å†å²tokençš„Kã€Vå€¼
- å¤§å¹…æå‡æ¨ç†é€Ÿåº¦
- å¯¹äºæ–‡æœ¬ç”Ÿæˆè‡³å…³é‡è¦

### 2. Flash Attention

```python
if self.flash and seq_len != 1:
    output = F.scaled_dot_product_attention(
        xq, xk, xv, 
        attn_mask=attn_mask, 
        dropout_p=dropout_p, 
        is_causal=True
    )
```

**Flash Attention ä¼˜åŠ¿**ï¼š
- å†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›è®¡ç®—
- å‡å°‘ä¸­é—´ç»“æœå­˜å‚¨
- æ”¯æŒæ›´é•¿åºåˆ—è®­ç»ƒ

### 3. MoEï¼ˆæ··åˆä¸“å®¶æ¨¡å‹ï¼‰æ”¯æŒ

```python
class MOEFeedForward(nn.Module):
    def __init__(self, config):
        # åˆ›å»ºå¤šä¸ªä¸“å®¶ç½‘ç»œ
        self.experts = nn.ModuleList([
            FeedForward(config) for _ in range(config.n_routed_experts)
        ])
        self.gate = MoEGate(config)  # è·¯ç”±ç½‘ç»œ
    
    def forward(self, x):
        # 1. é—¨æ§ç½‘ç»œé€‰æ‹©ä¸“å®¶
        topk_idx, topk_weight, aux_loss = self.gate(x)
        
        # 2. å°†tokenè·¯ç”±åˆ°å¯¹åº”ä¸“å®¶
        for i, expert in enumerate(self.experts):
            mask = (topk_idx == i)
            if mask.any():
                expert_output = expert(x[mask])
                # åŠ æƒç»„åˆä¸“å®¶è¾“å‡º
        
        return output
```

**MoE æ ¸å¿ƒæ€æƒ³**ï¼š
- æ¯ä¸ªtokenåªæ¿€æ´»å°‘æ•°å‡ ä¸ªä¸“å®¶
- å¢åŠ æ¨¡å‹å®¹é‡ä½†ä¿æŒè®¡ç®—é‡
- é€šè¿‡ä¸“ä¸šåŒ–æå‡æ¨¡å‹èƒ½åŠ›

## ğŸš€ è®­ç»ƒé…ç½®ä¸æ€§èƒ½ä¼˜åŒ–

### 1. è®­ç»ƒè¶…å‚æ•°

```python
# æ¨¡å‹é…ç½®
hidden_size = 512          # éšè—å±‚ç»´åº¦
num_hidden_layers = 8      # Transformerå±‚æ•°
num_attention_heads = 8    # æ³¨æ„åŠ›å¤´æ•°
vocab_size = 6400         # è¯æ±‡è¡¨å¤§å°

# è®­ç»ƒé…ç½®
batch_size = 32           # æ‰¹æ¬¡å¤§å°
learning_rate = 5e-4      # å­¦ä¹ ç‡
max_seq_len = 512         # æœ€å¤§åºåˆ—é•¿åº¦
accumulation_steps = 8    # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
```

### 2. åˆ†å¸ƒå¼è®­ç»ƒ

```python
# DDPé…ç½®
if ddp:
    model._ddp_params_and_buffers_to_ignore = {"pos_cis"}
    model = DistributedDataParallel(model, device_ids=[ddp_local_rank])
    
# æ•°æ®å¹¶è¡Œ
train_sampler = DistributedSampler(train_ds) if ddp else None
```

**åˆ†å¸ƒå¼è®­ç»ƒä¼˜åŠ¿**ï¼š
- å¤šGPUå¹¶è¡Œè®­ç»ƒ
- çº¿æ€§æå‡è®­ç»ƒé€Ÿåº¦
- æ”¯æŒæ›´å¤§æ¨¡å‹å’Œæ‰¹æ¬¡

### 3. æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜

```python
if (step + 1) % args.save_interval == 0:
    model.eval()
    moe_path = '_moe' if lm_config.use_moe else ''
    ckp = f'{args.save_dir}/pretrain_{lm_config.hidden_size}{moe_path}.pth'
    
    # è·å–æ¨¡å‹çŠ¶æ€å­—å…¸
    if isinstance(model, torch.nn.parallel.DistributedDataParallel):
        state_dict = model.module.state_dict()
    else:
        state_dict = model.state_dict()
    
    # åŠç²¾åº¦ä¿å­˜å‡å°‘å­˜å‚¨ç©ºé—´
    state_dict = {k: v.half() for k, v in state_dict.items()}
    torch.save(state_dict, ckp)
    model.train()
```

## ğŸ“ˆ è®­ç»ƒç›‘æ§ä¸è°ƒè¯•

### 1. å…³é”®æŒ‡æ ‡ç›‘æ§

```python
# è®­ç»ƒæŸå¤±
Logger(f'loss:{loss.item():.3f}')

# å­¦ä¹ ç‡
Logger(f'lr:{optimizer.param_groups[-1]["lr"]:.12f}')

# è®­ç»ƒé€Ÿåº¦
epoch_time = spend_time / (step + 1) * iter_per_epoch // 60
Logger(f'epoch_Time:{epoch_time}min')
```

### 2. WandBå¯è§†åŒ–

```python
if wandb is not None:
    wandb.log({
        "loss": loss.item() * args.accumulation_steps,
        "lr": optimizer.param_groups[-1]['lr'],
        "epoch_Time": epoch_time
    })
```

## ğŸ¯ é¢„è®­ç»ƒæ•ˆæœè¯„ä¼°

### 1. å›°æƒ‘åº¦(Perplexity)

```python
# å›°æƒ‘åº¦æ˜¯è¯„ä¼°è¯­è¨€æ¨¡å‹è´¨é‡çš„é‡è¦æŒ‡æ ‡
perplexity = torch.exp(loss)

# å›°æƒ‘åº¦è¶Šä½ï¼Œæ¨¡å‹å¯¹æ–‡æœ¬çš„é¢„æµ‹è¶Šå‡†ç¡®
# å¥½çš„æ¨¡å‹å›°æƒ‘åº¦é€šå¸¸åœ¨10-100ä¹‹é—´
```

### 2. æŸå¤±æ”¶æ•›

- **åˆå§‹æŸå¤±**ï¼šé€šå¸¸åœ¨8-10å·¦å³
- **æ”¶æ•›ç›®æ ‡**ï¼šæŸå¤±é™åˆ°2-4è¡¨ç¤ºæ¨¡å‹å­¦åˆ°äº†åŸºæœ¬è¯­è¨€è§„å¾‹
- **è¿‡æ‹Ÿåˆæ£€æŸ¥**ï¼šéªŒè¯é›†æŸå¤±ä¸åº”æŒç»­ä¸Šå‡

## ğŸ” å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### 1. æ˜¾å­˜ä¸è¶³

**é—®é¢˜è¡¨ç°**ï¼šCUDA out of memory

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å‡å°‘æ‰¹æ¬¡å¤§å°
batch_size = 16  # ä»32å‡å°‘åˆ°16

# å¢åŠ æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
accumulation_steps = 16  # ä»8å¢åŠ åˆ°16

# ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
model.gradient_checkpointing_enable()
```

### 2. è®­ç»ƒä¸æ”¶æ•›

**å¯èƒ½åŸå› **ï¼š
- å­¦ä¹ ç‡è¿‡å¤§ï¼šå°è¯• `1e-4` æˆ– `5e-5`
- æ¢¯åº¦çˆ†ç‚¸ï¼šæ£€æŸ¥æ¢¯åº¦è£å‰ªæ˜¯å¦ç”Ÿæ•ˆ
- æ•°æ®è´¨é‡ï¼šç¡®ä¿æ•°æ®é¢„å¤„ç†æ­£ç¡®

### 3. è®­ç»ƒé€Ÿåº¦æ…¢

**ä¼˜åŒ–å»ºè®®**ï¼š
- å¯ç”¨Flash Attention
- ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
- ä¼˜åŒ–æ•°æ®åŠ è½½å™¨ï¼ˆå¢åŠ num_workersï¼‰
- ä½¿ç”¨æ›´å¿«çš„å­˜å‚¨è®¾å¤‡

## ğŸ“š æ€»ç»“

MiniMindçš„é¢„è®­ç»ƒè¿‡ç¨‹å±•ç¤ºäº†ç°ä»£å¤§è¯­è¨€æ¨¡å‹çš„æ ¸å¿ƒæŠ€æœ¯ï¼š

1. **Transformeræ¶æ„**ï¼šå¤šå¤´æ³¨æ„åŠ›+å‰é¦ˆç½‘ç»œçš„ç»å…¸ç»„åˆ
2. **é«˜æ•ˆè®­ç»ƒ**ï¼šæ··åˆç²¾åº¦ã€æ¢¯åº¦ç´¯ç§¯ã€åˆ†å¸ƒå¼è®­ç»ƒ
3. **ä½ç½®ç¼–ç **ï¼šRoPEæä¾›æ›´å¥½çš„ä½ç½®ç†è§£
4. **ä¼˜åŒ–æŠ€æœ¯**ï¼šFlash Attentionã€KV-Cacheæå‡æ•ˆç‡
5. **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒMoEæ‰©å±•æ¨¡å‹å®¹é‡

é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼Œæ‚¨å¯ä»¥ï¼š
- ç†è§£è¯­è¨€æ¨¡å‹çš„å·¥ä½œåŸç†
- æŒæ¡PyTorchæ·±åº¦å­¦ä¹ å®è·µ
- å­¦ä¹ ç°ä»£AIè®­ç»ƒæŠ€æœ¯
- ä¸ºåç»­çš„å¾®è°ƒã€å¼ºåŒ–å­¦ä¹ æ‰“ä¸‹åŸºç¡€

**ä¸‹ä¸€æ­¥å­¦ä¹ å»ºè®®**ï¼š
1. å°è¯•ä¿®æ”¹æ¨¡å‹é…ç½®è¿›è¡Œå®éªŒ
2. å­¦ä¹ ç›‘ç£å¾®è°ƒ(SFT)è¿‡ç¨‹
3. äº†è§£RLHFå’ŒDPOç®—æ³•
4. æ¢ç´¢å¤šæ¨¡æ€æ¨¡å‹æ‰©å±•

å¸Œæœ›è¿™ä»½æ–‡æ¡£å¸®åŠ©æ‚¨æ·±å…¥ç†è§£MiniMindçš„é¢„è®­ç»ƒè¿‡ç¨‹ï¼å¦‚æœ‰ç–‘é—®ï¼Œæ¬¢è¿æŸ¥é˜…ä»£ç æˆ–è¿›è¡Œå®éªŒéªŒè¯ã€‚ 